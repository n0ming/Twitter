import pandas as pd
import spacy
from googletrans import Translator

nlp = spacy.load("en_core_web_sm")
translator = Translator()

def summarize(text):
    doc = nlp(text)
    checklist = []
    for sent in doc.sents:
        checklist.append(sent.text)
    return checklist

def translate(text):
    result = translator.translate(text, dest='ko')
    return result.text

# CSV 파일로부터 데이터를 읽어옴
data = pd.read_csv('ttwitter.csv')

# origincontent 열의 데이터를 체크리스트 항목으로 한국어로 정리
data['Translated_Content'] = data['Origin_Content'].apply(lambda x: '\n'.join([f"  - {translate(item)}" for item in summarize(str(x))]))

# Translated_Content 열과 날짜 열, AttachUrl, ImageUrl 열의 데이터만 출력
with open('aa.md', 'w', encoding='utf-8') as file:
    for index, row in data.iterrows():
        file.write(f"###{row['Date']}\n- [TAG]\n{row['Translated_Content']}\n")
        if pd.notnull(row['AttachUrl']):
            file.write(f"  - ({row['AttachUrl']})\n")
        if pd.notnull(row['ImageUrl']):
            file.write(f"  - ![Image]({row['ImageUrl']})\n\n")
        else:
            file.write("\n\n")
