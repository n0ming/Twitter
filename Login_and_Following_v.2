from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.action_chains import ActionChains
import random, time, pyperclip
from selenium import webdriver
from selenium.webdriver.common.proxy import Proxy, ProxyType
from selenium.common.exceptions import NoSuchElementException
file_path = "./tweet_total.txt"
def process_tweets_count(tweets_string):
    # "Tweets" 문자열을 제거하고 숫자 부분만 추출
    tweets_count = tweets_string.replace(" Tweets", "")

    # 'K'로 끝나는 경우 숫자를 1000배로 곱하여 'K'를 제거
    if tweets_count.endswith('K'):
        tweets_count = float(tweets_count[:-1]) * 1000

    return int(tweets_count)
def read_numbers_from_file(file_path):
    numbers = []
    with open(file_path, 'r') as file:
        for line in file:
            number = int(line.strip())
            numbers.append(number)
    return numbers
# Tor 브라우저 실행
#tor_proxy = "socks5://127.0.0.1:9160"  # Tor 브라우저의 프록시 주소
options = webdriver.ChromeOptions()
#options.add_argument('--proxy-server=%s' % tor_proxy)
browser = webdriver.Chrome(options=options)


# 브라우저를 주소창을 통해 로그인 페이지 접근
browser.get("https://twitter.com/snleeintern/following")

# 브라우저 묵시적 대기
browser.implicitly_wait(5)

# 랜덤시간 대기
time.sleep(random.randint(3, 5))

# 웹 페이지에서 id, pw 입력창 찾고 kisia 값 입력 후 랜덤시간 대기
id_ = browser.find_element(By.XPATH, '//input[@type="text"]')
pyperclip.copy("snleeintern")
id_.send_keys(Keys.CONTROL, 'v')
time.sleep(random.randint(1, 2))

btn_click = browser.find_element(By.CLASS_NAME, "css-18t94o4.css-1dbjc4n.r-sdzlij.r-1phboty.r-rs99b7.r-ywje51.r-usiww2.r-2yi16.r-1qi8awa.r-1ny4l3l.r-ymttw5.r-o7ynqc.r-6416eg.r-lrvibr.r-13qz1uu")
btn_click.click()

pw = browser.find_element(By.XPATH, '//input[@type="password"]')
pyperclip.copy("20111004")
pw.send_keys(Keys.CONTROL, 'v')
time.sleep(random.randint(1, 2))

# 로그인 버튼을 xpath로 찾고 클릭
login_button = browser.find_element(By.XPATH, '//*[@data-testid="LoginForm_Login_Button"]')
login_button.click()
try:
    element = browser.find_element(By.CLASS_NAME, "css-1dbjc4n.r-18u37iz.r-1pi2tsx.r-1wtj0ep.r-u8s1d.r-13qz1uu")
    print (element.text)
    if element.text == "휴대폰 번호":
        print("ok")
        input_element = browser.find_element(By.XPATH, "//input[@type='tel']")
        pyperclip.copy("01099274599")
        input_element.send_keys(Keys.CONTROL, 'v')
        time.sleep(random.randint(1, 2))

        btn_click = browser.find_element(By.XPATH, "//span[contains(text(), '다음')]")
        btn_click.click()
except NoSuchElementException:
    print("휴대폰 번호를 찾을 수 없습니다.")

# 팔로잉 계정 목록을 가져오기 위해 translateY()를 사용하여 페이지를 아래로 스크롤
def scroll_to_bottom():
    count =0
    SCROLL_PAUSE_TIME = 1
    last_height = browser.execute_script("return document.body.scrollHeight")
    while True:
        browser.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(SCROLL_PAUSE_TIME)
        new_height = browser.execute_script("return document.body.scrollHeight")
        if count == 3:
            break
        count+=1
        #if new_height == last_height:
        #    break
        last_height = new_height



# 팔로잉 계정의 리스트를 가져오기
following_list = browser.find_elements(By.XPATH, '//div[@data-testid="UserCell"]')

# Loop through each following account
for idx, _ in enumerate(following_list):
    # Re-fetch the following_list after scrolling to avoid StaleElementReferenceException
    following_list = browser.find_elements(By.XPATH, '//div[@data-testid="UserCell"]')

    # Click on the current following account using ActionChains
    following_account = following_list[idx]
    ActionChains(browser).move_to_element(following_account).click().perform()

    # Wait for the new page to load (You may adjust the wait time as needed)

    time.sleep(4)


    post_list = browser.find_elements(By.XPATH, '//div[@data-testid="tweet"]')

    # Loop through each post
    tweets_element = browser.find_element(By.CLASS_NAME, "css-901oao.css-1hf3ou5.r-14j79pv.r-37j5jr.r-n6v787.r-16dba41.r-1cwl3u0.r-bcqeeo.r-qvutc0")
    tweets_text = tweets_element.text
    print(tweets_text) 
    #result = process_tweets_count(tweets_text)
    #print(result)       
    #numbers_array = read_numbers_from_file(file_path)
    #print(result-numbers_array[0])
    #post_list = browser.find_elements(By.CLASS_NAME, "css-1dbjc4n.r-1loqt21.r-18u37iz.r-1ny4l3l.r-1udh08x.r-1qhn6m8.r-i023vh.r-o7ynqc.r-6416eg")
    post_list = browser.find_elements(By.XPATH, '//div[@data-testid="tweetText"]')

    # Loop through each post
    for idt, _ in enumerate(post_list):
        # Re-fetch the post_list after scrolling to avoid StaleElementReferenceException
        #post_list = browser.find_elements(By.CLASS_NAME, "css-1dbjc4n.r-1loqt21.r-18u37iz.r-1ny4l3l.r-1udh08x.r-1qhn6m8.r-i023vh.r-o7ynqc.r-6416eg")
        post_list = browser.find_elements(By.XPATH, '//div[@data-testid="tweetText"]')
        # Click on the current post using ActionChains
        post = post_list[idt]
        ActionChains(browser).move_to_element(post).click().perform()

        # Wait for the new page to load (You may adjust the wait time as needed)
        time.sleep(2)
        browser.execute_script("window.history.go(-1)")

            # Random wait before clicking the next post
        time.sleep(random.uniform(2, 4))




    # Do your desired actions here
    # For example, you can retrieve information or perform tasks on this page

    # Go back to the previous page (list of following accounts)
    browser.execute_script("window.history.go(-1)")

    # Random wait before clicking the next following account
    time.sleep(random.uniform(2, 4))


browser.close()

browser.close()
